import os
import time
import glob
import base64

import streamlit as st
from PIL import Image
import cv2
import numpy as np
import pytesseract
from googletrans import Translator
from gtts import gTTS

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(
    page_title="ğŸ“¸ OCR Traductor", 
    page_icon="ğŸ–¼ï¸", 
    layout="wide"
)

# Estilos y tipografÃ­a
st.markdown("""
<style>
  body { background-color: #ffffff; color: #000000; }
  .block-container { padding: 2rem 3rem; background: #f9f9f9; }
  h1, h2, h3, h4, h5 { color: #000000; }
  .stButton > button { color: #000000; border: 1px solid #000000; padding: 0.6rem 1.2rem; font-size: 1rem; }
  a { color: #000000; }
</style>
""", unsafe_allow_html=True)

# Banner
if os.path.exists('ocr_banner.png'):
    st.image('ocr_banner.png', use_column_width=True)

# TÃ­tulo
st.title("ğŸ–¼ï¸ OCR y Traductor de Texto en ImÃ¡genes")

# SelecciÃ³n de fuente de imagen
st.markdown("## ğŸ“¥ Carga o captura tu imagen")
mode = st.radio("Elige fuente:", ['ğŸ“· CÃ¡mara', 'ğŸ“ Cargar archivo'], index=1, horizontal=True)

if mode == 'ğŸ“· CÃ¡mara':
    img_buffer = st.camera_input("Toma una foto:")
else:
    img_buffer = st.file_uploader("Selecciona un archivo PNG/JPG:", type=['png','jpg'])

# Mostrar y procesar imagen
if img_buffer:
    file_bytes = img_buffer.getvalue()
    nparr = np.frombuffer(file_bytes, np.uint8)
    img_cv = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    st.image(img_cv, caption='ğŸ” Vista previa', use_column_width=True)

    # OCR
    st.markdown("## ğŸ” Reconociendo texto...")
    img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
    extracted = pytesseract.image_to_string(img_rgb)
    st.success("âœ… Texto extraÃ­do:")
    st.code(extracted, language='text')
else:
    extracted = ""

# Sidebar: parÃ¡metros de traducciÃ³n y audio
with st.sidebar:
    st.header("ğŸŒ ConfiguraciÃ³n de TraducciÃ³n")
    LANGS = {
        'ğŸ‡ªğŸ‡¸ EspaÃ±ol': 'es', 'ğŸ‡¬ğŸ‡§ English': 'en', 'ğŸ‡¨ğŸ‡³ ä¸­æ–‡': 'zh-cn',
        'ğŸ‡°ğŸ‡· í•œêµ­ì–´': 'ko', 'ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª': 'ja', 'ğŸ‡§ğŸ‡© à¦¬à¦¾à¦‚à¦²à¦¾': 'bn'
    }
    src_key = st.selectbox('ğŸ”„Idioma origen', list(LANGS.keys()), index=0)
    dst_key = st.selectbox('ğŸ”Idioma destino', list(LANGS.keys()), index=1)
    accent = st.selectbox('ğŸ“£ Acento (TLD)',['com','co.uk','com.au','ca','ie','co.za'], index=0)
    play = st.button('ğŸ§ Traducir y generar audio')
    remove_days = st.slider('ğŸ—‘ï¸Eliminar audios con mÃ¡s de dÃ­as:', 1, 30, 7)

# FunciÃ³n de texto a audio
def text_to_speech(text, src, dst, tld):
    translator = Translator()
    translated = translator.translate(text, src=src, dest=dst).text
    tts = gTTS(translated, lang=dst, tld=tld, slow=False)
    os.makedirs('temp', exist_ok=True)
    fname = f"ocr_{int(time.time())}.mp3"
    path = os.path.join('temp', fname)
    tts.save(path)
    return translated, path

# Al pulsar el botÃ³n
def handle_audio():
    if extracted.strip() == "":
        st.warning("ğŸ“‹ No hay texto para traducir.")
        return
    translated, audio_file = text_to_speech(
        extracted,
        src=LANGS[src_key],
        dst=LANGS[dst_key],
        tld=accent
    )
    st.balloons()
    st.markdown("## ğŸ“œ Texto traducido:")
    st.write(translated)
    audio_bytes = open(audio_file, 'rb').read()
    st.audio(audio_bytes)
    b64 = base64.b64encode(audio_bytes).decode()
    dl = f"<a href='data:audio/mp3;base64,{b64}' download='{os.path.basename(audio_file)}'>â¬‡ï¸ Descargar audio</a>"
    st.markdown(dl, unsafe_allow_html=True)

if play:
    handle_audio()

# Limpieza de archivos antiguos
def cleanup(days):
    cutoff = time.time() - days * 86400
    for f in glob.glob('temp/*.mp3'):
        if os.stat(f).st_mtime < cutoff:
            os.remove(f)

cleanup(remove_days)
